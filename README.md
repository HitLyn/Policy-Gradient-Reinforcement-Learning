Policy-Gradient-Methods\\

This repo contains code for actor-critic policy gradient methods in reinforcement learning (using least-squares temporal differnece learning with a linear function approximator) Contains code for:
The algorithms we consider include:
	1.	Episodic REINFORCE (Monte-Carlo) Actor-Critic Stochastic Policy Gradient
	2.	Vanilla Stochastic Policy Gradient
	3.	Vanilla Deterministic Policy Gradient
	4.	Vanilla Deterministic Policy Gradient with Exploratory Stochastic Policy
	5.	Natural Stochastic Policy Gradient
	6.	Natural Deterministic Policy Gradient
	7.	Deterministic Policy Gradient Algorithm With Line Search Optimization
	8.	Stochastic Policy Gradient Algorithm with Line Search Optimization
	9.	Deterministic Policy Gradient Algorithm with "vanilla" gradient ascent
	10.	Stochastic Policy Gradient Algorithm with "vanilla" gradient ascent
	11.	Deterministic Policy Gradients with Momentum-Based Nesterov's Accelerated Gradient
	12.	Stochastic Policy Gradients with Momentum-Based Nesterov's Accelerated Gradient
We consider the following MDPs using a Parameterized Controller (Agent):
	1.	Toy MDP
	2.	Grid World (10x10) MDP
	3.	Mountain Car MDP
	4.	Cart Pole MDP
	5.	Pendulum MDP
